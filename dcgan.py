# -*- coding: utf-8 -*-
"""DCGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ps85L1jyLQP3lvTVGZWxDjJAyZ6FCUFH
"""

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
from tensorflow.keras import layers as layer
import os
import time
from IPython import display
dataset, info = tfds.load('celeb_a', split='train', with_info=True, shuffle_files=True)

def preprocess(features):
    image = features['image']
    # Crop center 178x178 (original size 218 height)
    # central_fraction = 178 / 218 ~ 0.8165
    image = tf.image.central_crop(image, central_fraction=178/218)
    #image resize
    image = tf.image.resize(image, [64, 64])
    image = tf.cast(image, tf.float32)
    image = (image - 127.5) / 127.5
    return image

batch_size=64
train_dataset=dataset.map(preprocess,num_parallel_calls=tf.data.AUTOTUNE)
train_dataset=train_dataset.shuffle(1000).batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)
for images in train_dataset.take(1):
    print(images.shape)
    imgs = (images + 1.0) / 2.0

    fig, axes = plt.subplots(1, 8, figsize=(12, 4))
    for i in range(8):
        axes[i].imshow(imgs[i])
        axes[i].axis('off')
    plt.show()

def generator_model():
    model = tf.keras.Sequential()
    model.add(layer.Dense(8*8*256,use_bias=False,input_shape=(100,)))
    model.add(layer.BatchNormalization())
    model.add(layer.LeakyReLU())

    model.add(layer.Reshape((8,8,256)))
    assert model.output_shape == (None,8,8,256)

    model.add(layer.Conv2DTranspose(128,(5,5),strides=(2,2),padding='same',use_bias=False))
    assert model.output_shape == (None,16,16,128)
    model.add(layer.BatchNormalization())
    model.add(layer.LeakyReLU())

    model.add(layer.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))
    assert model.output_shape == (None,32,32,64)
    model.add(layer.BatchNormalization())
    model.add(layer.LeakyReLU())

    model.add(layer.Conv2DTranspose(3,(5,5),strides=(2,2),padding='same',use_bias=False,activation='tanh'))
    assert model.output_shape == (None,64,64,3)

    return model

def discriminator_model():
    model=tf.keras.Sequential()
    model.add(layer.Conv2D(64,(5,5),strides=(2,2),padding='same',input_shape=[64,64,3]))

    model.add(layer.LeakyReLU())
    model.add(layer.Dropout(0.3))

    model.add(layer.Conv2D(128,(5,5),strides=(2,2),padding='same'))
    model.add(layer.LeakyReLU())
    model.add(layer.Dropout(0.3))

    model.add(layer.Flatten())
    model.add(layer.Dense(1))

    return model

generator=generator_model()
discriminator=discriminator_model()

cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output,fake_output):
    real_loss=cross_entropy(tf.ones_like(real_output),real_output)
    fake_loss=cross_entropy(tf.zeros_like(fake_output),fake_output)
    total_loss=real_loss+fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output),fake_output)

generator_optimizer=tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer=tf.keras.optimizers.Adam(1e-4)

checkpoint_dir = r'C:\ML\checkpoints'
os.makedirs(checkpoint_dir, exist_ok=True)

checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')
checkpoint = tf.train.Checkpoint(
    generator_optimizer=generator_optimizer,
    discriminator_optimizer=discriminator_optimizer,
    generator=generator,
    discriminator=discriminator
)
checkpoint.save(file_prefix=checkpoint_prefix)

epochs=8
noise_dim=100
num_examples=16
seed=tf.random.normal([num_examples,noise_dim])
gen_losses = []
disc_losses = []

def train_step(images):
    noise = tf.random.normal([batch_size, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    return gen_loss, disc_loss

def generate_and_save_images(model,epoch,test_input):
    predictions=model(test_input,training=False)
    fig=plt.figure(figsize=(4,4))

    for i in range(predictions.shape[0]):
        plt.subplot(4,4,i+1)
        plt.imshow((predictions[i,:,:,:] + 1.0) / 2.0)
        plt.axis('off')
    plt.savefig(r'C:\Users\shado\Pictures\Screenshots\image_at_epoch_{:04d}.png'.format(epoch))
    plt.show()

def train(dataset,epochs):
    for epoch in range(epochs):
        start=time.time()
        for image_batch in dataset:
            gen_loss,disc_loss=train_step(image_batch)
            gen_losses.append(gen_loss.numpy())
            disc_losses.append(disc_loss.numpy())
        generate_and_save_images(generator,epoch+1,seed)
        if(epoch+1)%5==0:
            checkpoint.save(file_prefix=checkpoint_prefix)
        print(f'Epoch {epoch+1}, Gen Loss: {gen_losses[-1]:.4f}, Disc Loss: {disc_losses[-1]:.4f}, Time: {time.time()-start:.2f} sec')
    generate_and_save_images(generator,epochs,seed)
    print(f'Epoch {epoch+1}, Gen Loss: {gen_losses[-1]:.4f}, Disc Loss: {disc_losses[-1]:.4f}, Time: {time.time()-start:.2f} sec')

train(train_dataset,epochs)

latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)
if latest_checkpoint:
    checkpoint.restore(latest_checkpoint)
    print(f"Checkpoint from {latest_checkpoint}")
else:
    print("No checkpoint found.")

print(gen_losses[-1])
print(disc_losses[-1])

def test_generator(generator, n_images=16, noise_dim=100):
    noise = tf.random.normal([n_images, noise_dim])
    generated_images = generator(noise, training=False)

    # Normalize the images for display,they are in [-1, 1]
    generated_images = (generated_images + 1) / 2.0

    plt.figure(figsize=(4, 4))
    for i in range(n_images):
        plt.subplot(4, 4, i+1)
        plt.imshow(generated_images[i, :, :, :])
        plt.axis('off')
    plt.suptitle("Generated Images")
    plt.show()

test_generator(generator)